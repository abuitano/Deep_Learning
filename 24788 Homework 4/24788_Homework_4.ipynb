{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vezeaTvhASid"
      },
      "source": [
        "# Question 3 Flower Classification using CNN \n",
        "- Please **do not** change the default variable names in this problem, as we will use them in different parts.\n",
        "- The default variables are initially set to \"None\".\n",
        "- You only need to modify code in the \"TODO\" part. We added some \"assertions\" to check your code. **Do not** modify them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obpyErWGZMyo"
      },
      "source": [
        "# import statements\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import random \n",
        "from tqdm import tqdm \n",
        "import warnings\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cA6R2cVIMom"
      },
      "source": [
        "You can upload your image folder on Google drive and access image folder from it. **Skip it if you run on local machine.** You May: \n",
        "\n",
        "*   Mount google drive to your current colab page.\n",
        "*   Mount it on google colab's local storage and unzip the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niU6h2jiET_8"
      },
      "source": [
        "#TODO\n",
        "# run the following command to mount data through Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# OR uncomment following code, upload the dataset zip file, unzip by running the following code\n",
        "# ! unzip ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check pytorch cuda and use cuda if possible\n",
        "device = torch.cuda.is_available()\n",
        "print('*' * 50)\n",
        "if device:  \n",
        "  print('CUDA is found! Tranining on %s.......'%torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  warnings.warn('CUDA not found! Training may be slow......')"
      ],
      "metadata": {
        "id": "lOaDzS5Kn-hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I21FUvr9BCTq"
      },
      "source": [
        "\n",
        "## P1. Data augmentation and plotting\n",
        "### TODO\n",
        "- Design your image augmentation method for transform_image\n",
        "- Load train and test data, and split them into train_loader and test_loader \n",
        "- Visualize your augmented image \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0FPwP6bbJHn"
      },
      "source": [
        "# TODO: define your image augmentation method\n",
        "# Make sure to crop the image in (3,224,224) using transforms.RandomResizedCrop(224)  \n",
        "transform_image = None\n",
        "\n",
        "# TODO: Load data using ImageFolder. Specify your image folder path \n",
        "path = None\n",
        "dataset = datasets.ImageFolder(path,transform=transform_image)\n",
        "\n",
        "n = len(dataset)\n",
        "n_test = int(0.1 * n) \n",
        "\n",
        "# Split data into features(pixels) and labels(numbers from 0 to 4)\n",
        "train_dataset, test_dataset = random_split(dataset, (n-n_test,n_test))\n",
        "train_loader, test_loader = DataLoader(train_dataset, batch_size=16, shuffle=True), DataLoader(test_dataset, batch_size=16, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RXfRWmaJTF_"
      },
      "source": [
        "# Sample output\n",
        "label_map = [['daisy'],['dandelion'],['rose'],['sunflower'],['tulip']]\n",
        "random_image = random.randint(0,len(train_dataset))\n",
        "image = train_dataset.__getitem__(random_image)\n",
        "assert np.array_equal(image[0].detach().numpy().shape, [3,224,224])\n",
        "plt.imshow(image[0].permute(1,2,0))\n",
        "plt.title(f\"Training Example\")\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6mtpsr-CR4U"
      },
      "source": [
        "## P2. Build you own CNN model \n",
        "### TODO\n",
        "- Design your own model class in **CNNModel(nn.Module)** and write forward pass in **forward(self, x)**\n",
        "- Create loss function in **criterion**, optimizer in **optimizer**\n",
        "- Define hyparparameters: **learning_rate**, **num_epochs**\n",
        "- Plot your **loss vs num_epochs** and **accuracy vs num_epochs** \n",
        "- Plot your first convolution layer kernels using **plot_filters_multi_channel()**\n",
        "\n",
        "###  Hints\n",
        "- Start with low number of epochs for debugging. (eg. num_epochs=1)\n",
        "- You may want to use small learning rate for training. (eg. 1e-5)\n",
        "- Be careful with the input dimension of fully connected layer. \n",
        "- The dimension calculation of the output tensor from the input tensor is \\\\\n",
        "$D_{out}=\\frac{D_{in}-K+2P}{S}+1$ \\\\\n",
        "$D_{out}$ : Dimension of output tensor \\\\\n",
        "$D_{in}$ : Dimension of input tensor \\\\\n",
        "$K$ : width/height of the kernel \\\\\n",
        "$S$ : stride \\\\\n",
        "$P$ : padding\n",
        "\n",
        "## Convolutional and Pooling Layers\n",
        "\n",
        "A convolutional layer using pyTorch:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "torch.nn.Conv2d(num_in_channels, num_out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
        "```\n",
        "For example:\n",
        "```\n",
        "torch.nn.Conv2d(3, 32, 3)\n",
        "```\n",
        "It applies a 2D convolution over an input signal composed of several input planes. If we have input size with $(N, C_{in}, H, W)$ and output size with $(N, C_{out}, H_{out}, W_{out})$, the 2D convolution can described as $$out(N_i, C_{out_j}) = bias(C_{out_j}) + \\sum_{k=0}^{C_{in}-1}weight(C_{out_j},k)\\star input(N_i,k)$$\n",
        "\n",
        "**num_in_channels:** is the number of channels of the input tensor. If the previous layer is the input layer, num_in_channels is the number of channels of the image (3 channels for RGB images), otherwise num_in_channels is equal to the number of feature maps of the previous layer.\n",
        "\n",
        "**num_out_channels:** is the number of filters (feature extractor) that this layer will apply over the image or feature maps generated by the previous layer.\n",
        "\n",
        "**kernel_size:** is the size of the convolving kernel\n",
        "So for instance, if we have an RGB image and we are going to apply 32 filters of 3x3:\n",
        "\n",
        "**stide:** is the stride of the convolution. Default: 1\n",
        "\n",
        "**padding:** is the padding added to all four sides of the input. Default: 0\n",
        "\n",
        "**dilation:** is the spacing between kernel elements. Default: 1\n",
        "\n",
        "**group:** is the number of blocked connections from input channels to output channels. Default: 1\n",
        "\n",
        "**bias:** If True, adds a learnable bias to the output. Default: True\n",
        "\n",
        "## A Simple Convolutional Neural Network\n",
        "\n",
        "In our convnet we'll use the next structure shown in the comment:\n",
        "\n",
        "*input -> convolution -> pooling -> fully connected -> output* \\\\\n",
        "\n",
        "**Convolution #1**\n",
        "\n",
        "16 kernels of 5x5; *Width/Height:* (224 - 5 + 2x0) / 1 + 1 = 220; *Output dimensions:* (16, 220, 220)\n",
        "\n",
        "**Max Pooling #1**\n",
        "\n",
        "filter size = 2, stride = 2; *Width/Height:* (220 - 2) / 2 + 1 = 110; *Output dimensions:* (16, 110, 110)\n",
        "\n",
        "So at the end of the last convolutional layer we get a tensor of dimension (16, 110, 110). And since now we are going to feed it to fully connected classifier, we need to convert it into a 1-D vector, and for that we use the reshape method:\n",
        "\n",
        "```\n",
        "x = x.view(x.size(0), -1)\n",
        "```\n",
        "The way of calculating size of the output size from previous convolution layer can be formulized as below: $$H_{output} = \\frac{H_{in}+2\\times padding-kernel\\_Size}{stride}+1$$\n",
        "\n",
        "For more details, you can refer to this link: \\\\\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrvosNegfTaU"
      },
      "source": [
        "class CNNModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNNModel, self).__init__()\n",
        "    # TODO: Create CNNModel using 2D convolution. You should vary the number of convolution layers and fully connected layers \n",
        "    # Example:  \n",
        "    # self.cnn1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
        "    # self.relu1 = nn.ReLU() \n",
        "    # self.maxpool1 = nn.MaxPool2d(kernel_size=2) \n",
        "    self.cnn1 = None     \n",
        "    \n",
        "    # TODO: Create Fully connected layers. You should calculate the dimension of the input tensor from the previous layer \n",
        "    # Example: \n",
        "    # self.fc1 = nn.Linear(16 *110 * 110, 5)\n",
        "    # Fully connected 1\n",
        "    self.fc1 = None\n",
        "\n",
        "  def forward(self,x):\n",
        "    # TODO: Perform forward pass in blow section \n",
        "    # Example:\n",
        "    # out = self.cnn1(x)\n",
        "    # out = self.relu1(out)      \n",
        "    # out = self.maxpool1(out) \n",
        "    # out = out.view(out.size(0), -1)\n",
        "    # out = self.fc1(out)\n",
        "    \n",
        "    out = None\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa6w_m3WAz3P"
      },
      "source": [
        "## Starting Up Our Model\n",
        "\n",
        "We'll send the model to our GPU if you have one so we need to create a CUDA device and instantiate our model. Then we will define the loss function and \n",
        "hyperparameters that we need to train the model: \\\\\n",
        "\n",
        "###TODO\n",
        "- Define Cross Entropy Loss\n",
        "- Create Adam Optimizer\n",
        "- Define hyperparameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfJseAOtgA_N"
      },
      "source": [
        "# Create CNN\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = CNNModel()\n",
        "model.to(device)\n",
        "\n",
        "# TODO: define Cross Entropy Loss \n",
        "criterion = None\n",
        "\n",
        "# TODO: create Adam Optimizer and define your hyperparameters \n",
        "learning_rate = None\n",
        "optimizer = None\n",
        "num_epochs = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiIreB-YAdV4"
      },
      "source": [
        "### Training the Model\n",
        "### TODO \n",
        "- Make predictions from your model\n",
        "- Calculate Cross Entropy Loss from predictions and labels "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYHpNCnogtNQ"
      },
      "source": [
        "count = 0\n",
        "loss_list = []\n",
        "iteration_list = []\n",
        "accuracy_list = []\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    model.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        # Clear gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # TODO: Forward propagation\n",
        "        outputs = None\n",
        "        \n",
        "        # TODO: Calculate softmax and Cross entropy loss\n",
        "        loss = None\n",
        "        \n",
        "        # Backprop agate your Loss \n",
        "        loss.backward()\n",
        "        \n",
        "        # Update CNN model  \n",
        "        optimizer.step()\n",
        "        \n",
        "        count += 1\n",
        "        \n",
        "        if count % 50 == 0:\n",
        "            model.eval()\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                \n",
        "                # Forward propagation\n",
        "                outputs = model(images)\n",
        "                \n",
        "                # Get predictions from the maximum value\n",
        "                predicted = torch.argmax(outputs, 1)\n",
        "                \n",
        "                # Total number of labels\n",
        "                total += len(labels)\n",
        "                \n",
        "                correct += (predicted == labels).sum()\n",
        "            \n",
        "            accuracy = 100 * correct / float(total)\n",
        "            \n",
        "            # store loss and iteration\n",
        "            loss_list.append(loss.data)\n",
        "            iteration_list.append(count)\n",
        "            accuracy_list.append(accuracy)\n",
        "        if count % 500 == 0:\n",
        "            # Print Loss\n",
        "            print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data, accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the Data\n",
        "### TODO\n",
        "\n",
        "\n",
        "*   Plot Accuracy versus Iterations Graph\n",
        "*   Plot Loss versus Iterations Graph\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QXSbHJGKisPV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz-jrjkDg4Uq"
      },
      "source": [
        "# visualization accuracy\n",
        "#TODO: Plot Accuracy versus Iterations\n",
        "\n",
        "# visualization loss\n",
        "#TODO: Plot Loss versus Iterations \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}