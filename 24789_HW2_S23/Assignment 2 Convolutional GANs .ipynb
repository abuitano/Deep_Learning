{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch Size \n",
    "batch_size = 128\n",
    "image_size = 64\n",
    "workers = 2\n",
    "\n",
    "numchannels = 3 #Number of channels \n",
    "latent = 100 #Latent Space Size \n",
    "gen_feat = 64 # Size of feature maps in generator \n",
    "dis_feat = 64 # Size of feature maps in discriminator \n",
    "\n",
    "# Number of gpus available. Use 0 for cpu.\n",
    "num_gpu = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impliment data transforms and loading\n",
    "\n",
    "#TODO\n",
    "dataroot = 'Add Path' #Add your file path here\n",
    "transforms = transforms.Compose() #Add Transforms\n",
    "\n",
    "dataset = dset.ImageFolder(root=dataroot, transform=transforms)\n",
    "\n",
    "# Create the dataloader\n",
    "#TODO\n",
    "dataloader = torch.utils.data.DataLoader()#Add dataloader\n",
    "\n",
    "#Select device\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and num_gpu > 0) else \"cpu\")\n",
    "\n",
    "#Display real images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight initialization for Generator and Discriminator no changes required \n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_gpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.num_gpu = num_gpu\n",
    "        self.main = nn.Sequential(\n",
    "            #Create Generator using ConvTranspose2d\n",
    "            #TODO\n",
    "            \n",
    "            #One example layer\n",
    "            nn.ConvTranspose2d(latent, gen_feat * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(gen_feat * 8),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator\n",
    "netG = Generator(num_gpu).to(device)\n",
    "\n",
    "#Device selection\n",
    "if (device.type == 'cuda') and (num_gpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(num_gpu)))\n",
    "\n",
    "netG.apply(weights_init)\n",
    "\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_gpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.num_gpu = num_gpu\n",
    "        self.main = nn.Sequential(\n",
    "            #Create Discriminator using Conv2d\n",
    "            #TODO\n",
    "            \n",
    "            #One example layer\n",
    "            nn.Conv2d(numchannels, dis_feat, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator(num_gpu).to(device)\n",
    "\n",
    "#Device Selection\n",
    "if (device.type == 'cuda') and (num_gpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(num_gpu)))\n",
    "\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Loss Function\n",
    "#TODO\n",
    "criterion = 'None'\n",
    "\n",
    "fixed_noise = torch.randn(64, latent, 1, 1, device=device)\n",
    "\n",
    "#Real and fake labels for training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Setup optimizers for Generator and Discriminator \n",
    "#TODO\n",
    "optimizerD = 'None'\n",
    "optimizerG = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "num_epochs = 1 \n",
    "lr = 0.0003\n",
    "beta1 = 0.5\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        ## Train with all-real batch\n",
    "        \n",
    "        #Train Discriminator\n",
    "        #TODO \n",
    "\n",
    "\n",
    "        # Generate fake images \n",
    "        #TODO\n",
    "\n",
    "\n",
    "        #Train Generator\n",
    "        #TODO\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        #Record Losses to Plot\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Your Generator and Discriminator Loss\n",
    "#No Changes Needed\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake Images Grid \n",
    "#No Changes Needed\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,1,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
